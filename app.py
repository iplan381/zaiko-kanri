import streamlit as st
import pandas as pd
import datetime as dt 
import base64
import requests
from io import StringIO

def get_now_jst():
    return dt.datetime.now(dt.timezone(dt.timedelta(hours=9))).strftime("%Y-%m-%d %H:%M")

# --- 1. è¨­å®š ---
REPO_NAME = "iplan381/zaiko-kanri" 
FILE_PATH_STOCK = "inventory_main.csv"
FILE_PATH_LOG = "stock_log_main.csv"
GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]

SIZES_MASTER = ["å¤§", "ä¸­", "å°", "4å€‹å…¥", " - "]
VENDORS_MASTER = ["å¯Œå£«å±±", "æ±å±±è¦³å…‰", "ãƒ¢ãƒ³ãƒ†ãƒªã‚¢", "ãƒ™ãƒ¼ã‚«ãƒªãƒ¼"]
USERS = ["ä½è—¤", "æ‰‹å¡š", "æª€åŸ"]

st.set_page_config(page_title="åœ¨åº«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")

# --- 2. GitHubé–¢æ•° ---
def get_github_data(file_path):
    url = f"https://api.github.com/repos/{REPO_NAME}/contents/{file_path}"
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    res = requests.get(url, headers=headers)
    if res.status_code == 200:
        content = res.json()
        csv_text = base64.b64decode(content["content"]).decode("utf-8")
        df = pd.read_csv(StringIO(csv_text))
        return df.fillna(""), content["sha"]
    return pd.DataFrame(), None

def update_github_data(file_path, df, sha, message):
    url = f"https://api.github.com/repos/{REPO_NAME}/contents/{file_path}"
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    csv_content = df.to_csv(index=False)
    data = {
        "message": message,
        "content": base64.b64encode(csv_content.encode("utf-8")).decode("utf-8"),
        "sha": sha
    }
    res = requests.put(url, headers=headers, json=data)
    return res.status_code == 200

def get_opts(series):
    items = sorted([str(x) for x in series.unique() if str(x).strip() != ""])
    return ["ã™ã¹ã¦"] + items

# ğŸ’¡ ã‚¢ãƒ©ãƒ¼ãƒˆèƒŒæ™¯è‰²ã®è¨­å®šï¼ˆå¾©æ´»ï¼‰
def highlight_alert(row):
    styles = [''] * len(row)
    col_names = row.index.tolist()
    if "åœ¨åº«æ•°" in col_names:
        stock_idx = col_names.index("åœ¨åº«æ•°")
        styles[stock_idx] = 'background-color: #262730; color: white; font-weight: bold;' 
        if row["åœ¨åº«æ•°"] <= row["ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–"]:
            return ['background-color: #d9534f; color: white'] * len(row)
    return styles

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df_stock, sha_stock = get_github_data(FILE_PATH_STOCK)
df_log, sha_log = get_github_data(FILE_PATH_LOG)

# --- 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("âœ¨ æ–°è¦å•†å“ç™»éŒ²")
    n_item = st.text_input("å•†å“å ")
    n_size = st.selectbox("ã‚µã‚¤ã‚º ", SIZES_MASTER)
    n_loc = st.text_input("åœ°å ")
    n_vendor = st.selectbox("å–å¼•å…ˆ ", VENDORS_MASTER)
    n_stock = st.number_input("åˆæœŸåœ¨åº«", min_value=0, value=0)
    n_alert = st.number_input("ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–", min_value=0, value=5)
    
    if st.button("æ–°è¦ç™»éŒ²å®Ÿè¡Œ", use_container_width=True, type="primary"):
        is_duplicate = not df_stock[(df_stock["å•†å“å"] == n_item) & (df_stock["ã‚µã‚¤ã‚º"] == n_size) & (df_stock["åœ°å"] == n_loc)].empty
        if is_duplicate:
            st.error(f"âŒ é‡è¤‡ã‚¨ãƒ©ãƒ¼")
        elif n_item and n_loc:
            now = get_now_jst()
            new_row = pd.DataFrame([{"æœ€çµ‚æ›´æ–°æ—¥": now, "å•†å“å": n_item, "ã‚µã‚¤ã‚º": n_size, "åœ°å": n_loc, "åœ¨åº«æ•°": n_stock, "ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–": n_alert, "å–å¼•å…ˆ": n_vendor}])
            new_log = pd.DataFrame([{"æ—¥æ™‚": now, "å•†å“å": n_item, "ã‚µã‚¤ã‚º": n_size, "åœ°å": n_loc, "åŒºåˆ†": "æ–°è¦ç™»éŒ²", "æ•°é‡": n_stock, "æ‹…å½“è€…": "ã‚·ã‚¹ãƒ†ãƒ "}])
            if update_github_data(FILE_PATH_STOCK, pd.concat([df_stock, new_row], ignore_index=True), sha_stock, "Add Item") and \
               update_github_data(FILE_PATH_LOG, pd.concat([df_log, new_log], ignore_index=True), sha_log, "Add Log"):
                st.success("ç™»éŒ²å®Œäº†")
                st.rerun()
    
    st.divider()
    sync_logs = st.checkbox("å±¥æ­´ã‚‚åœ¨åº«æ¤œç´¢ã¨é€£å‹•ã•ã›ã‚‹", value=True)

# --- 4. ãƒ¡ã‚¤ãƒ³ï¼šåœ¨åº«ä¸€è¦§ ---
st.title("ğŸ“¦ åœ¨åº«ç®¡ç†")
st.subheader("ğŸ“Š åœ¨åº«ä¸€è¦§")

c1, c2, c3, c4 = st.columns(4)
with c1: s_item = st.selectbox("æ¤œç´¢:å•†å“å", get_opts(df_stock["å•†å“å"]))
with c2: s_size = st.selectbox("æ¤œç´¢:ã‚µã‚¤ã‚º", get_opts(df_stock["ã‚µã‚¤ã‚º"]))
with c3: search_loc = st.text_input("æ¤œç´¢:åœ°åï¼ˆæ‰‹å…¥åŠ›ï¼‰", placeholder="ä¾‹: é’æ£®")
with c4: s_vendor = st.selectbox("æ¤œç´¢:å–å¼•å…ˆ", get_opts(df_stock["å–å¼•å…ˆ"]))

df_disp = df_stock.copy()
if s_item != "ã™ã¹ã¦": df_disp = df_disp[df_disp["å•†å“å"] == s_item]
if s_size != "ã™ã¹ã¦": df_disp = df_disp[df_disp["ã‚µã‚¤ã‚º"] == s_size]
if search_loc.strip(): df_disp = df_disp[df_disp["åœ°å"].astype(str).str.contains(search_loc, na=False)]
if s_vendor != "ã™ã¹ã¦": df_disp = df_disp[df_disp["å–å¼•å…ˆ"] == s_vendor]

df_disp = df_disp.sort_values("æœ€çµ‚æ›´æ–°æ—¥", ascending=False)
styled_df = df_disp.style.apply(highlight_alert, axis=1)

# ğŸ’¡ è¤‡æ•°é¸æŠå¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤ºï¼ˆã‚¢ãƒ©ãƒ¼ãƒˆè‰²ç¶­æŒï¼‰
event = st.dataframe(
    styled_df, use_container_width=True, hide_index=True, on_select="rerun", selection_mode="multi-row",
    column_config={"æœ€çµ‚æ›´æ–°æ—¥": "æ—¥æ™‚", "åœ¨åº«æ•°": "åœ¨åº«", "æ•°é‡": st.column_config.NumberColumn(format="%d")}
)

# --- 5. æ“ä½œãƒ‘ãƒãƒ«ï¼šå€‹åˆ¥ä¸€æ‹¬å…¥åŠ› ---
st.divider()
selected_indices = event.selection.rows
selected_data_list = df_disp.iloc[selected_indices] if selected_indices else pd.DataFrame()

if not selected_data_list.empty:
    n_selected = len(selected_data_list)
    st.markdown(f"### ğŸ“‹ {n_selected} ä»¶ã®ä¸€æ‹¬æ“ä½œ")
    
    # æ‹…å½“è€…ã®è¨˜æ†¶
    user_list = ["-- é¸æŠ --"] + USERS
    default_user_idx = 0
    if "last_user" in st.session_state and st.session_state.last_user in user_list:
        default_user_idx = user_list.index(st.session_state.last_user)
    
    user_name = st.selectbox("æ‹…å½“è€…ã‚’é¸ã‚“ã§ã‹ã‚‰å…¥åŠ›ã—ã¦ãã ã•ã„", user_list, index=default_user_idx)
    
    if user_name != "-- é¸æŠ --":
        st.info("ğŸ’¡ å•†å“ã”ã¨ã«æ•°é‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        
        # ğŸ’¡ å„å•†å“ã”ã¨ã®å…¥åŠ›æ¬„ã‚’å‹•çš„ã«ç”Ÿæˆ
        update_values = {}
        for idx_in_list, row in selected_data_list.iterrows():
            item_label = f"{row['å•†å“å']} ({row['ã‚µã‚¤ã‚º']} / {row['åœ°å']})"
            col_info, col_radio, col_qty = st.columns([2, 1, 1])
            with col_info:
                st.write(f"**{item_label}**")
                st.caption(f"ç¾åœ¨ã®åœ¨åº«: {row['åœ¨åº«æ•°']}")
            with col_radio:
                m_type = st.radio(f"åŒºåˆ†_{idx_in_list}", ["å…¥åº«", "å‡ºåº«", "å¤‰æ›´ãªã—"], horizontal=True, label_visibility="collapsed")
            with col_qty:
                m_qty = st.number_input(f"æ•°é‡_{idx_in_list}", min_value=0, value=0, label_visibility="collapsed")
            
            update_values[idx_in_list] = {"type": m_type, "qty": m_qty}
            st.divider()
        
        if st.button("ğŸ’¾ å…¨ã¦ã®å¤‰æ›´ã‚’ç¢ºå®šã™ã‚‹", type="primary", use_container_width=True):
            st.session_state.last_user = user_name
            now = get_now_jst()
            new_logs = []
            
            for idx_in_list, vals in update_values.items():
                if vals["type"] == "å¤‰æ›´ãªã—": continue
                
                row = selected_data_list.loc[idx_in_list]
                # å…ƒã®df_stockã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¢ã™
                orig_idx = df_stock[(df_stock["å•†å“å"] == row["å•†å“å"]) & (df_stock["ã‚µã‚¤ã‚º"] == row["ã‚µã‚¤ã‚º"]) & (df_stock["åœ°å"] == row["åœ°å"])].index[0]
                
                qty = vals["qty"]
                if vals["type"] == "å…¥åº«":
                    df_stock.at[orig_idx, "åœ¨åº«æ•°"] += qty
                elif vals["type"] == "å‡ºåº«":
                    df_stock.at[orig_idx, "åœ¨åº«æ•°"] -= qty
                
                df_stock.at[orig_idx, "æœ€çµ‚æ›´æ–°æ—¥"] = now
                
                if qty > 0:
                    new_logs.append({
                        "æ—¥æ™‚": now, "å•†å“å": row["å•†å“å"], "ã‚µã‚¤ã‚º": row["ã‚µã‚¤ã‚º"], "åœ°å": row["åœ°å"],
                        "åŒºåˆ†": vals["type"], "æ•°é‡": qty, "æ‹…å½“è€…": user_name
                    })
            
            if update_github_data(FILE_PATH_STOCK, df_stock, sha_stock, "Multi Update") and \
               (not new_logs or update_github_data(FILE_PATH_LOG, pd.concat([df_log, pd.DataFrame(new_logs)], ignore_index=True), sha_log, "Multi Log")):
                st.rerun()
else:
    st.write("ğŸ’¡ **è¡¨ã®å·¦ç«¯ã§è¤‡æ•°ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã‚‹ã¨ã€ãã‚Œãã‚Œé•ã†æ•°é‡ã§ä¸€æ°—ã«å…¥åº«ãƒ»å‡ºåº«ã§ãã¾ã™ã€‚**")

# --- 6. å±¥æ­´è¡¨ç¤º ---
st.divider()
log_h_col1, log_h_col2, log_h_col3 = st.columns([1.5, 2, 2])
with log_h_col1:
    st.subheader("ğŸ“œ å…¥å‡ºåº«å±¥æ­´")
with log_h_col2:
    log_types = st.multiselect("åŒºåˆ†:", ["å…¥åº«", "å‡ºåº«", "ç·¨é›†", "æ–°è¦ç™»éŒ²"], default=["å…¥åº«", "å‡ºåº«", "æ–°è¦ç™»éŒ²"], label_visibility="collapsed")
with log_h_col3:
    log_date_range = st.date_input("æœŸé–“é¸æŠ", value=(dt.date.today() - dt.timedelta(days=7), dt.date.today()), label_visibility="collapsed")

if not df_log.empty:
    df_log_filt = df_log.copy()
    if isinstance(log_date_range, tuple) and len(log_date_range) == 2:
        start_date, end_date = log_date_range
        df_log_filt["æ—¥æ™‚_dt"] = pd.to_datetime(df_log_filt["æ—¥æ™‚"]).dt.date
        df_log_filt = df_log_filt[(df_log_filt["æ—¥æ™‚_dt"] >= start_date) & (df_log_filt["æ—¥æ™‚_dt"] <= end_date)]
    if log_types:
        df_log_filt = df_log_filt[df_log_filt["åŒºåˆ†"].isin(log_types)]
    if sync_logs:
        if s_item != "ã™ã¹ã¦": df_log_filt = df_log_filt[df_log_filt["å•†å“å"] == s_item]
        if s_size != "ã™ã¹ã¦": df_log_filt = df_log_filt[df_log_filt["ã‚µã‚¤ã‚º"] == s_size]
        if search_loc.strip(): df_log_filt = df_log_filt[df_log_filt["åœ°å"].astype(str).str.contains(search_loc, na=False)]

    st.dataframe(
        df_log_filt[["æ—¥æ™‚", "å•†å“å", "ã‚µã‚¤ã‚º", "åœ°å", "åŒºåˆ†", "æ•°é‡", "æ‹…å½“è€…"]].sort_values("æ—¥æ™‚", ascending=False), 
        use_container_width=True, hide_index=True,
        column_config={"æ•°é‡": st.column_config.NumberColumn("æ•°", format="%d")}
    )
