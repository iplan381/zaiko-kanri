import streamlit as st
import pandas as pd
import datetime as dt 
import base64
import requests
from io import StringIO

def get_now_jst():
    return dt.datetime.now(dt.timezone(dt.timedelta(hours=9))).strftime("%Y-%m-%d %H:%M")

# --- 1. è¨­å®š ---
REPO_NAME = "iplan381/zaiko-kanri" 
FILE_PATH_STOCK = "inventory_main.csv"
FILE_PATH_LOG = "stock_log_main.csv"
FILE_PATH_RESERVATION = "reservations_main.csv" # ğŸ’¡ äºˆç´„ç”¨ãƒ‘ã‚¹ã‚’è¿½åŠ 
GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]

SIZES_MASTER = ["å¤§", "ä¸­", "å°", "4å€‹å…¥", " - "]
VENDORS_MASTER = ["å¯Œå£«å±±", "æ±å±±è¦³å…‰", "ãƒ¢ãƒ³ãƒ†ãƒªã‚¢", "ãƒ™ãƒ¼ã‚«ãƒªãƒ¼"]
USERS = ["ä½è—¤", "æ‰‹å¡š", "æª€åŸ"]

st.set_page_config(page_title="åœ¨åº«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")

# --- 2. GitHubé–¢æ•° ---
def get_github_data(file_path):
    url = f"https://api.github.com/repos/{REPO_NAME}/contents/{file_path}"
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    res = requests.get(url, headers=headers)
    if res.status_code == 200:
        content = res.json()
        csv_text = base64.b64decode(content["content"]).decode("utf-8")
        df = pd.read_csv(StringIO(csv_text))
        return df.fillna(""), content["sha"]
    return pd.DataFrame(), None

def update_github_data(file_path, df, sha, message):
    url = f"https://api.github.com/repos/{REPO_NAME}/contents/{file_path}"
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    csv_content = df.to_csv(index=False)
    data = {
        "message": message,
        "content": base64.b64encode(csv_content.encode("utf-8")).decode("utf-8"),
        "sha": sha
    }
    res = requests.put(url, headers=headers, json=data)
    return res.status_code == 200

# ğŸ’¡ 2. äºˆç´„ã‚’è‡ªå‹•å‡¦ç†ã™ã‚‹é–¢æ•°
def process_reservations(df_stock, sha_stock, df_log, sha_log):
    df_res, sha_res = get_github_data(FILE_PATH_RESERVATION)
    if df_res.empty: return df_stock, df_log
    
    # ä»Šæ—¥ã®æ—¥ä»˜ã‚’å–å¾—
    today = dt.datetime.now(dt.timezone(dt.timedelta(hours=9))).date()
    df_res["äºˆç´„æ—¥_dt"] = pd.to_datetime(df_res["äºˆç´„æ—¥"]).dt.date
    
    # ä»Šæ—¥ä»¥å‰ï¼ˆå½“æ—¥å«ã‚€ï¼‰ã®äºˆç´„ã‚’æŠ½å‡º
    to_process = df_res[df_res["äºˆç´„æ—¥_dt"] <= today]
    
    if not to_process.empty:
        new_logs = []
        for _, row in to_process.iterrows():
            mask = (df_stock["å•†å“å"] == row["å•†å“å"]) & (df_stock["ã‚µã‚¤ã‚º"] == row["ã‚µã‚¤ã‚º"]) & (df_stock["åœ°å"] == row["åœ°å"])
            if mask.any():
                idx = df_stock[mask].index[0]
                df_stock.at[idx, "åœ¨åº«æ•°"] -= row["æ•°é‡"]
                df_stock.at[idx, "æœ€çµ‚æ›´æ–°æ—¥"] = get_now_jst()
                new_logs.append({
                    "æ—¥æ™‚": get_now_jst(), "å•†å“å": row["å•†å“å"], "ã‚µã‚¤ã‚º": row["ã‚µã‚¤ã‚º"], 
                    "åœ°å": row["åœ°å"], "åŒºåˆ†": "å‡ºåº«(äºˆç´„å®Ÿè¡Œ)", "æ•°é‡": row["æ•°é‡"], "æ‹…å½“è€…": row["æ‹…å½“è€…"]
                })
        
        # å‡¦ç†ãŒçµ‚ã‚ã£ãŸã‚‚ã®ã‚’å‰Šé™¤ã—ã¦æ›´æ–°
        df_res_remain = df_res[df_res["äºˆç´„æ—¥_dt"] > today].drop(columns=["äºˆç´„æ—¥_dt"])
        update_github_data(FILE_PATH_STOCK, df_stock, sha_stock, "Auto Reservation Executed")
        update_github_data(FILE_PATH_LOG, pd.concat([df_log, pd.DataFrame(new_logs)], ignore_index=True), sha_log, "Auto Res Log")
        update_github_data(FILE_PATH_RESERVATION, df_res_remain, sha_res, "Clean up Reservation")
        st.success(f"ğŸ“¢ æœ¬æ—¥ã®å‡ºåº«äºˆç´„ï¼ˆ{len(to_process)}ä»¶ï¼‰ã‚’åœ¨åº«ã«åæ˜ ã—ã¾ã—ãŸï¼")
        st.rerun()
    return df_stock, df_log

def get_opts(series):
    items = sorted([str(x) for x in series.unique() if str(x).strip() != ""])
    return ["ã™ã¹ã¦"] + items

def highlight_alert(row):
    styles = [''] * len(row)
    col_names = row.index.tolist()
    if "åœ¨åº«æ•°" in col_names:
        stock_idx = col_names.index("åœ¨åº«æ•°")
        styles[stock_idx] = 'background-color: #262730; color: white; font-weight: bold;' 
        if row["åœ¨åº«æ•°"] < row["ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–"]:
            return ['background-color: #d9534f; color: white'] * len(row)
    return styles

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df_stock, sha_stock = get_github_data(FILE_PATH_STOCK)
df_log, sha_log = get_github_data(FILE_PATH_LOG)

# ğŸ’¡ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ç›´å¾Œã«äºˆç´„ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
df_stock, df_log = process_reservations(df_stock, sha_stock, df_log, sha_log)

# --- 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("âœ¨ æ–°è¦å•†å“ç™»éŒ²")
    n_item = st.text_input("å•†å“å", key="new_item_input") # keyã‚’è¿½åŠ ã—ã¦é‡è¤‡ã‚’å›é¿
    n_size = st.selectbox("ã‚µã‚¤ã‚º", SIZES_MASTER, key="new_size_input")
    n_loc = st.text_input("åœ°å", key="new_loc_input")
    n_vendor = st.selectbox("å–å¼•å…ˆ", VENDORS_MASTER, key="new_vendor_input")
    n_stock = st.number_input("åˆæœŸåœ¨åº«", min_value=0, value=0, key="new_stock_input")
    n_alert = st.number_input("ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–", min_value=0, value=5, key="new_alert_input")
    
    if st.button("æ–°è¦ç™»éŒ²å®Ÿè¡Œ", use_container_width=True, type="primary"):
        is_duplicate = not df_stock[(df_stock["å•†å“å"] == n_item) & (df_stock["ã‚µã‚¤ã‚º"] == n_size) & (df_stock["åœ°å"] == n_loc)].empty
        if is_duplicate:
            st.error(f"âŒ é‡è¤‡ã‚¨ãƒ©ãƒ¼")
        elif n_item and n_loc:
            now = get_now_jst()
            new_row = pd.DataFrame([{"æœ€çµ‚æ›´æ–°æ—¥": now, "å•†å“å": n_item, "ã‚µã‚¤ã‚º": n_size, "åœ°å": n_loc, "åœ¨åº«æ•°": n_stock, "ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–": n_alert, "å–å¼•å…ˆ": n_vendor}])
            new_log = pd.DataFrame([{"æ—¥æ™‚": now, "å•†å“å": n_item, "ã‚µã‚¤ã‚º": n_size, "åœ°å": n_loc, "åŒºåˆ†": "æ–°è¦ç™»éŒ²", "æ•°é‡": n_stock, "æ‹…å½“è€…": "ã‚·ã‚¹ãƒ†ãƒ "}])
            if update_github_data(FILE_PATH_STOCK, pd.concat([df_stock, new_row], ignore_index=True), sha_stock, "Add Item") and \
               update_github_data(FILE_PATH_LOG, pd.concat([df_log, pd.DataFrame(new_log)], ignore_index=True), sha_log, "Add Log"):
                st.success("ç™»éŒ²å®Œäº†")
                st.rerun()
    
    st.divider()
    sync_logs = st.checkbox("å±¥æ­´ã‚‚åœ¨åº«æ¤œç´¢ã¨é€£å‹•ã•ã›ã‚‹", value=True)

# --- 4. ãƒ¡ã‚¤ãƒ³ï¼šåœ¨åº«ä¸€è¦§ ---
st.title("ğŸ“¦ åœ¨åº«ç®¡ç†")
st.subheader("ğŸ“Š åœ¨åº«ä¸€è¦§")

c1, c2, c3, c4 = st.columns(4)
with c1: s_item = st.selectbox("æ¤œç´¢:å•†å“å", get_opts(df_stock["å•†å“å"]), key="filter_item")
with c2: s_size = st.selectbox("æ¤œç´¢:ã‚µã‚¤ã‚º", get_opts(df_stock["ã‚µã‚¤ã‚º"]), key="filter_size")
with c3: search_loc = st.text_input("æ¤œç´¢:åœ°åï¼ˆæ‰‹å…¥åŠ›ï¼‰", placeholder="ä¾‹: é’æ£®", key="filter_loc")
with c4: s_vendor = st.selectbox("æ¤œç´¢:å–å¼•å…ˆ", get_opts(df_stock["å–å¼•å…ˆ"]), key="filter_vendor")

# --- 5. æ“ä½œãƒ‘ãƒãƒ«ï¼šä¸€æ‹¬ç·¨é›† ---
# (ã“ã“ã‹ã‚‰å…ˆã¯å‰å›ãŠé€ã‚Šã—ãŸã€Œæ•°é‡ã€ãŒå‡ºã‚‹ã‚³ãƒ¼ãƒ‰ã«ç¹‹ãŒã‚Šã¾ã™)
