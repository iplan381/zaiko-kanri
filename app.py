import streamlit as st
import pandas as pd
import datetime as dt 
import base64
import requests
from io import StringIO

def get_now_jst():
    return dt.datetime.now(dt.timezone(dt.timedelta(hours=9))).strftime("%Y-%m-%d %H:%M")

# --- 1. è¨­å®š ---
REPO_NAME = "iplan381/zaiko-kanri" 
FILE_PATH_STOCK = "inventory_main.csv"
FILE_PATH_LOG = "stock_log_main.csv"
FILE_PATH_RESERVATION = "reservations_main.csv"
GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]

SIZES_MASTER = ["å¤§", "ä¸­", "å°", "4å€‹å…¥", " - "]
VENDORS_MASTER = ["å¯Œå£«å±±", "æ±å±±è¦³å…‰", "ãƒ¢ãƒ³ãƒ†ãƒªã‚¢", "ãƒ™ãƒ¼ã‚«ãƒªãƒ¼"]
USERS = ["ä½è—¤", "æ‰‹å¡š", "æª€åŸ"]

st.set_page_config(page_title="åœ¨åº«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")

# --- 2. GitHubé–¢æ•° ---
def get_github_data(file_path):
    url = f"https://api.github.com/repos/{REPO_NAME}/contents/{file_path}"
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    res = requests.get(url, headers=headers)
    if res.status_code == 200:
        content = res.json()
        csv_text = base64.b64decode(content["content"]).decode("utf-8")
        df = pd.read_csv(StringIO(csv_text))
        return df.fillna(""), content["sha"]
    return pd.DataFrame(), None

def update_github_data(file_path, df, sha, message):
    url = f"https://api.github.com/repos/{REPO_NAME}/contents/{file_path}"
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    csv_content = df.to_csv(index=False)
    data = {
        "message": message,
        "content": base64.b64encode(csv_content.encode("utf-8")).decode("utf-8"),
        "sha": sha
    }
    res = requests.put(url, headers=headers, json=data)
    return res.status_code == 200

def process_reservations(df_stock, sha_stock, df_log, sha_log):
    df_res, sha_res = get_github_data(FILE_PATH_RESERVATION)
    if df_res.empty: return df_stock, df_log
    today = dt.datetime.now(dt.timezone(dt.timedelta(hours=9))).date()
    df_res["äºˆç´„æ—¥_dt"] = pd.to_datetime(df_res["äºˆç´„æ—¥"]).dt.date
    to_process = df_res[df_res["äºˆç´„æ—¥_dt"] <= today]
    if not to_process.empty:
        new_logs = []
        for _, row in to_process.iterrows():
            mask = (df_stock["å•†å“å"] == row["å•†å“å"]) & (df_stock["ã‚µã‚¤ã‚º"] == row["ã‚µã‚¤ã‚º"]) & (df_stock["åœ°å"] == row["åœ°å"])
            if mask.any():
                idx = df_stock[mask].index[0]
                df_stock.at[idx, "åœ¨åº«æ•°"] -= row["æ•°é‡"]
                df_stock.at[idx, "æœ€çµ‚æ›´æ–°æ—¥"] = get_now_jst()
                new_logs.append({
                    "æ—¥æ™‚": get_now_jst(), "å•†å“å": row["å•†å“å"], "ã‚µã‚¤ã‚º": row["ã‚µã‚¤ã‚º"], 
                    "åœ°å": row["åœ°å"], "åŒºåˆ†": "å‡ºåº«(äºˆç´„å®Ÿè¡Œ)", "æ•°é‡": row["æ•°é‡"], 
                    "åœ¨åº«æ•°": df_stock.at[idx, "åœ¨åº«æ•°"], "æ‹…å½“è€…": row["æ‹…å½“è€…"]
                })
        df_res_remain = df_res[df_res["äºˆç´„æ—¥_dt"] > today].drop(columns=["äºˆç´„æ—¥_dt"])
        update_github_data(FILE_PATH_STOCK, df_stock, sha_stock, "Auto Res Exec")
        update_github_data(FILE_PATH_LOG, pd.concat([df_log, pd.DataFrame(new_logs)], ignore_index=True), sha_log, "Auto Res Log")
        update_github_data(FILE_PATH_RESERVATION, df_res_remain, sha_res, "Clean Res")
        st.success(f"ğŸ“¢ æœ¬æ—¥ã®äºˆç´„ã‚’åæ˜ ã—ã¾ã—ãŸ")
        st.rerun()
    return df_stock, df_log

def get_opts(series):
    items = sorted([str(x) for x in series.unique() if str(x).strip() != ""])
    return ["ã™ã¹ã¦"] + items

def highlight_alert(row):
    styles = [''] * len(row)
    # â˜…ã‚¢ãƒ©ãƒ¼ãƒˆåˆ¤å®šã‚’ã€Œæœ‰åŠ¹åœ¨åº«ã€ã«å¤‰æ›´
    if "æœ‰åŠ¹åœ¨åº«" in row.index and row["æœ‰åŠ¹åœ¨åº«"] < row["ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–"]:
        return ['background-color: #d9534f; color: white'] * len(row)
    return styles

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
df_stock, sha_stock = get_github_data(FILE_PATH_STOCK)
df_log, sha_log = get_github_data(FILE_PATH_LOG)
df_res_all, sha_res_all = get_github_data(FILE_PATH_RESERVATION)
df_stock, df_log = process_reservations(df_stock, sha_stock, df_log, sha_log)

# --- 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("âœ¨ æ–°è¦å•†å“ç™»éŒ²")
    n_item = st.text_input("å•†å“å", key="s_n_item")
    n_size = st.selectbox("ã‚µã‚¤ã‚º", SIZES_MASTER, key="s_n_size")
    n_loc = st.text_input("åœ°å", key="s_n_loc")
    n_vendor = st.selectbox("å–å¼•å…ˆ", VENDORS_MASTER, key="s_n_vendor")
    n_stock = st.number_input("åˆæœŸåœ¨åº«", min_value=0, value=0, key="s_n_stock")
    n_alert = st.number_input("ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–", min_value=0, value=5, key="s_n_alert")
    if st.button("ç™»éŒ²å®Ÿè¡Œ", use_container_width=True, type="primary"):
        if n_item and n_loc:
            now = get_now_jst()
            new_row = pd.DataFrame([{"æœ€çµ‚æ›´æ–°æ—¥": now, "å•†å“å": n_item, "ã‚µã‚¤ã‚º": n_size, "åœ°å": n_loc, "åœ¨åº«æ•°": n_stock, "ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–": n_alert, "å–å¼•å…ˆ": n_vendor}])
            update_github_data(FILE_PATH_STOCK, pd.concat([df_stock, new_row], ignore_index=True), sha_stock, "Add")
            st.rerun()

# --- 4. ãƒ¡ã‚¤ãƒ³ ---
st.title("ğŸ“¦ åœ¨åº«ç®¡ç†")

c1, c2, c3 = st.columns(3)
with c1: s_item = st.selectbox("å•†å“å", get_opts(df_stock["å•†å“å"]), key="f_item")
with c2: s_size = st.selectbox("ã‚µã‚¤ã‚º", get_opts(df_stock["ã‚µã‚¤ã‚º"]), key="f_size")
with c3: s_loc = st.text_input("åœ°åæ¤œç´¢", placeholder="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", key="f_loc")

# æœ‰åŠ¹åœ¨åº«ã®è¨ˆç®—
df_disp = df_stock.copy()
res_sum = df_res_all.groupby(["å•†å“å", "ã‚µã‚¤ã‚º", "åœ°å"])["æ•°é‡"].sum().reset_index().rename(columns={"æ•°é‡": "äºˆç´„è¨ˆ"})
df_disp = pd.merge(df_disp, res_sum, on=["å•†å“å", "ã‚µã‚¤ã‚º", "åœ°å"], how="left").fillna({"äºˆç´„è¨ˆ": 0})
df_disp["æœ‰åŠ¹åœ¨åº«"] = df_disp["åœ¨åº«æ•°"] - df_disp["äºˆç´„è¨ˆ"]

if s_item != "ã™ã¹ã¦": df_disp = df_disp[df_disp["å•†å“å"] == s_item]
if s_size != "ã™ã¹ã¦": df_disp = df_disp[df_disp["ã‚µã‚¤ã‚º"] == s_size]
if s_loc.strip(): df_disp = df_disp[df_disp["åœ°å"].astype(str).str.contains(s_loc, na=False)]

# ä¸€è¦§è¡¨ç¤º
disp_cols = ["å•†å“å", "ã‚µã‚¤ã‚º", "åœ°å", "åœ¨åº«æ•°", "æœ‰åŠ¹åœ¨åº«", "ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–"]
df_show = df_disp[disp_cols].sort_values("å•†å“å")
styled_df = df_show.style.apply(highlight_alert, axis=1)

event = st.dataframe(
    styled_df, use_container_width=True, hide_index=True, on_select="rerun", selection_mode="multi-row",
    column_config={
        "åœ¨åº«æ•°": st.column_config.NumberColumn("å®Ÿåœ¨åº«", format="%d"),
        "æœ‰åŠ¹åœ¨åº«": st.column_config.NumberColumn("æœ‰åŠ¹åœ¨åº«", format="%d")
    }
)

# --- 5. æ“ä½œãƒ‘ãƒãƒ« ---
st.divider()
selected_indices = event.selection.rows
if selected_indices:
    selected_data_list = df_show.iloc[selected_indices]
    st.markdown(f"### ğŸ“‹ {len(selected_data_list)} ä»¶ã®æ“ä½œ")
    user_name = st.selectbox("æ‹…å½“è€…", ["-- é¸æŠ --"] + USERS)
    
    if user_name != "-- é¸æŠ --":
        update_payload = {}
        for i, row in selected_data_list.iterrows():
            with st.expander(f"ğŸ“Œ {row['å•†å“å']} ({row['ã‚µã‚¤ã‚º']} / {row['åœ°å']})", expanded=True):
                col1, col2, col3, col4, col5 = st.columns([1.5, 1, 1.2, 1, 0.6])
                with col1: m_type = st.radio("åŒºåˆ†", ["å…¥åº«", "å‡ºåº«", "äºˆç´„å‡ºåº«", "å¤‰æ›´ãªã—"], horizontal=True, key=f"t_{i}")
                with col2: m_qty = st.number_input("æ•°é‡", min_value=0, key=f"q_{i}")
                with col3:
                    if m_type == "äºˆç´„å‡ºåº«":
                        res_date = st.date_input("äºˆç´„æ—¥", value=dt.date.today() + dt.timedelta(days=1), key=f"d_{i}")
                    else:
                        new_loc = st.text_input("åœ°åå¤‰æ›´", value=row['åœ°å'], key=f"l_{i}")
                with col4: new_alt = st.number_input("åŸºæº–", min_value=0, value=int(row['ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–']), key=f"a_{i}")
                with col5: is_del = st.checkbox("å‰Šé™¤", key=f"del_{i}")
                update_payload[idx] = {"type": m_type, "qty": m_qty, "loc": new_loc if m_type != "äºˆç´„å‡ºåº«" else row['åœ°å'], "alert": new_alt, "delete": is_del, "res_date": res_date if m_type == "äºˆç´„å‡ºåº«" else None, "orig_data": row}

        if st.button("ğŸ”„ ç¢ºå®š", type="primary", use_container_width=True):
            now = get_now_jst()
            new_logs, new_res = [], []
            for idx, p in update_payload.items():
                row = p["orig_data"]
                mask = (df_stock["å•†å“å"] == row["å•†å“å"]) & (df_stock["ã‚µã‚¤ã‚º"] == row["ã‚µã‚¤ã‚º"]) & (df_stock["åœ°å"] == row["åœ°å"])
                if mask.any():
                    oidx = df_stock[mask].index[0]
                    if p["delete"]:
                        df_stock = df_stock.drop(oidx)
                        new_logs.append({"æ—¥æ™‚": now, "å•†å“å": row["å•†å“å"], "ã‚µã‚¤ã‚º": row["ã‚µã‚¤ã‚º"], "åœ°å": row["åœ°å"], "åŒºåˆ†": "å‰Šé™¤", "æ•°é‡": 0, "åœ¨åº«æ•°": 0, "æ‹…å½“è€…": user_name})
                    elif p["type"] == "äºˆç´„å‡ºåº«" and p["qty"] > 0:
                        new_res.append({"äºˆç´„æ—¥": p["res_date"], "å•†å“å": row["å•†å“å"], "ã‚µã‚¤ã‚º": row["ã‚µã‚¤ã‚º"], "åœ°å": row["åœ°å"], "æ•°é‡": p["qty"], "æ‹…å½“è€…": user_name})
                    elif p["type"] != "å¤‰æ›´ãªã—":
                        if p["type"] == "å…¥åº«": df_stock.at[oidx, "åœ¨åº«æ•°"] += p["qty"]
                        elif p["type"] == "å‡ºåº«": df_stock.at[oidx, "åœ¨åº«æ•°"] -= p["qty"]
                        df_stock.at[oidx, "åœ°å"], df_stock.at[oidx, "ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–"], df_stock.at[oidx, "æœ€çµ‚æ›´æ–°æ—¥"] = p["loc"], p["alert"], now
                        
                        curr_stock = df_stock.at[oidx, "åœ¨åº«æ•°"]
                        if p["qty"] > 0: 
                            new_logs.append({"æ—¥æ™‚": now, "å•†å“å": row["å•†å“å"], "ã‚µã‚¤ã‚º": row["ã‚µã‚¤ã‚º"], "åœ°å": p["loc"], "åŒºåˆ†": p["type"], "æ•°é‡": p["qty"], "åœ¨åº«æ•°": curr_stock, "æ‹…å½“è€…": user_name})
                        if p["loc"] != row["åœ°å"]: 
                            new_logs.append({"æ—¥æ™‚": now, "å•†å“å": row["å•†å“å"], "ã‚µã‚¤ã‚º": row["ã‚µã‚¤ã‚º"], "åœ°å": p["loc"], "åŒºåˆ†": "åœ°åå¤‰æ›´", "æ•°é‡": 0, "åœ¨åº«æ•°": curr_stock, "æ‹…å½“è€…": user_name})
            
            update_github_data(FILE_PATH_STOCK, df_stock, sha_stock, "Update")
            if new_logs: update_github_data(FILE_PATH_LOG, pd.concat([df_log, pd.DataFrame(new_logs)], ignore_index=True), sha_log, "Log Update")
            if new_res:
                df_res_old, sha_res = get_github_data(FILE_PATH_RESERVATION)
                update_github_data(FILE_PATH_RESERVATION, pd.concat([df_res_old, pd.DataFrame(new_res)], ignore_index=True), sha_res, "Add Res")
            st.rerun()

# --- 6. äºˆç´„ãƒ»å±¥æ­´ ---
col_res, col_log = st.columns(2)
with col_res:
    st.subheader("ğŸ“… å‡ºåº«äºˆç´„")
    if not df_res_all.empty:
        df_rv = df_res_all.copy()
        df_rv["äºˆç´„æ—¥"] = pd.to_datetime(df_rv["äºˆç´„æ—¥"]).dt.date
        res_sel = st.dataframe(df_rv.sort_values("äºˆç´„æ—¥"), use_container_width=True, hide_index=True, on_select="rerun", selection_mode="multi-row")
        if res_sel.selection.rows:
            if st.button("ğŸ—‘ï¸ äºˆç´„å–æ¶ˆ"):
                update_github_data(FILE_PATH_RESERVATION, df_rv.drop(df_rv.index[res_sel.selection.rows]), sha_res_all, "Del Res")
                st.rerun()
with col_log:
    st.subheader("ğŸ“œ å±¥æ­´")
    if not df_log.empty:
        disp_log_cols = ["æ—¥æ™‚", "åŒºåˆ†", "å•†å“å", "æ•°é‡", "åœ¨åº«æ•°", "æ‹…å½“è€…"]
        if "åœ¨åº«æ•°" not in df_log.columns: df_log["åœ¨åº«æ•°"] = ""
        st.dataframe(df_log[[c for c in disp_log_cols if c in df_log.columns]].sort_values("æ—¥æ™‚", ascending=False), 
                     use_container_width=True, hide_index=True, 
                     column_config={"æ•°é‡": "æ•°", "åœ¨åº«æ•°": "ç¾åœ¨åº«"})
