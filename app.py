import streamlit as st
import pandas as pd
import datetime as dt 
import base64
import requests
from io import StringIO

def get_now_jst():
    return dt.datetime.now(dt.timezone(dt.timedelta(hours=9))).strftime("%Y-%m-%d %H:%M")

# --- 1. è¨­å®š ---
REPO_NAME = "iplan381/zaiko-kanri" 
FILE_PATH_STOCK = "inventory_main.csv"
FILE_PATH_LOG = "stock_log_main.csv"
GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]

SIZES_MASTER = ["å¤§", "ä¸­", "å°", "4å€‹å…¥", " - "]
VENDORS_MASTER = ["å¯Œå£«å±±", "æ±å±±è¦³å…‰", "ãƒ¢ãƒ³ãƒ†ãƒªã‚¢", "ãƒ™ãƒ¼ã‚«ãƒªãƒ¼"]
USERS = ["ä½è—¤", "æ‰‹å¡š", "æª€åŸ"]

st.set_page_config(page_title="åœ¨åº«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")

# --- 2. GitHubé–¢æ•° ---
def get_github_data(file_path):
    url = f"https://api.github.com/repos/{REPO_NAME}/contents/{file_path}"
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    res = requests.get(url, headers=headers)
    if res.status_code == 200:
        content = res.json()
        csv_text = base64.b64decode(content["content"]).decode("utf-8")
        df = pd.read_csv(StringIO(csv_text))
        return df.fillna(""), content["sha"]
    return pd.DataFrame(), None

def update_github_data(file_path, df, sha, message):
    url = f"https://api.github.com/repos/{REPO_NAME}/contents/{file_path}"
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    csv_content = df.to_csv(index=False)
    data = {
        "message": message,
        "content": base64.b64encode(csv_content.encode("utf-8")).decode("utf-8"),
        "sha": sha
    }
    res = requests.put(url, headers=headers, json=data)
    return res.status_code == 200

def get_opts(series):
    items = sorted([str(x) for x in series.unique() if str(x).strip() != ""])
    return ["ã™ã¹ã¦"] + items

def highlight_alert(row):
    styles = [''] * len(row)
    col_names = row.index.tolist()
    if "åœ¨åº«æ•°" in col_names:
        stock_idx = col_names.index("åœ¨åº«æ•°")
        styles[stock_idx] = 'background-color: #262730; color: white; font-weight: bold;' 
        if row["åœ¨åº«æ•°"] < row["ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–"]:
            return ['background-color: #d9534f; color: white'] * len(row)
    return styles

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df_stock, sha_stock = get_github_data(FILE_PATH_STOCK)
df_log, sha_log = get_github_data(FILE_PATH_LOG)

# --- 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("âœ¨ æ–°è¦å•†å“ç™»éŒ²")
    n_item = st.text_input("å•†å“å ")
    n_size = st.selectbox("ã‚µã‚¤ã‚º ", SIZES_MASTER)
    n_loc = st.text_input("åœ°å ")
    n_vendor = st.selectbox("å–å¼•å…ˆ ", VENDORS_MASTER)
    n_stock = st.number_input("åˆæœŸåœ¨åº«", min_value=0, value=0)
    n_alert = st.number_input("ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–", min_value=0, value=5)
    
    if st.button("æ–°è¦ç™»éŒ²å®Ÿè¡Œ", use_container_width=True, type="primary"):
        is_duplicate = not df_stock[(df_stock["å•†å“å"] == n_item) & (df_stock["ã‚µã‚¤ã‚º"] == n_size) & (df_stock["åœ°å"] == n_loc)].empty
        if is_duplicate:
            st.error(f"âŒ é‡è¤‡ã‚¨ãƒ©ãƒ¼")
        elif n_item and n_loc:
            now = get_now_jst()
            new_row = pd.DataFrame([{"æœ€çµ‚æ›´æ–°æ—¥": now, "å•†å“å": n_item, "ã‚µã‚¤ã‚º": n_size, "åœ°å": n_loc, "åœ¨åº«æ•°": n_stock, "ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–": n_alert, "å–å¼•å…ˆ": n_vendor}])
            new_log = pd.DataFrame([{"æ—¥æ™‚": now, "å•†å“å": n_item, "ã‚µã‚¤ã‚º": n_size, "åœ°å": n_loc, "åŒºåˆ†": "æ–°è¦ç™»éŒ²", "æ•°é‡": n_stock, "æ‹…å½“è€…": "ã‚·ã‚¹ãƒ†ãƒ "}])
            if update_github_data(FILE_PATH_STOCK, pd.concat([df_stock, new_row], ignore_index=True), sha_stock, "Add Item") and \
               update_github_data(FILE_PATH_LOG, pd.concat([df_log, new_log], ignore_index=True), sha_log, "Add Log"):
                st.success("ç™»éŒ²å®Œäº†")
                st.rerun()
    
    st.divider()
    sync_logs = st.checkbox("å±¥æ­´ã‚‚åœ¨åº«æ¤œç´¢ã¨é€£å‹•ã•ã›ã‚‹", value=True)

# --- 4. ãƒ¡ã‚¤ãƒ³ï¼šåœ¨åº«ä¸€è¦§ ---
st.title("ğŸ“¦ åœ¨åº«ç®¡ç†")
st.subheader("ğŸ“Š åœ¨åº«ä¸€è¦§")

c1, c2, c3, c4 = st.columns(4)
with c1: s_item = st.selectbox("æ¤œç´¢:å•†å“å", get_opts(df_stock["å•†å“å"]))
with c2: s_size = st.selectbox("æ¤œç´¢:ã‚µã‚¤ã‚º", get_opts(df_stock["ã‚µã‚¤ã‚º"]))
with c3: search_loc = st.text_input("æ¤œç´¢:åœ°åï¼ˆæ‰‹å…¥åŠ›ï¼‰", placeholder="ä¾‹: é’æ£®")
with c4: s_vendor = st.selectbox("æ¤œç´¢:å–å¼•å…ˆ", get_opts(df_stock["å–å¼•å…ˆ"]))

df_disp = df_stock.copy()
if s_item != "ã™ã¹ã¦": df_disp = df_disp[df_disp["å•†å“å"] == s_item]
if s_size != "ã™ã¹ã¦": df_disp = df_disp[df_disp["ã‚µã‚¤ã‚º"] == s_size]
if search_loc.strip(): df_disp = df_disp[df_disp["åœ°å"].astype(str).str.contains(search_loc, na=False)]
if s_vendor != "ã™ã¹ã¦": df_disp = df_disp[df_disp["å–å¼•å…ˆ"] == s_vendor]

df_disp = df_disp.sort_values("æœ€çµ‚æ›´æ–°æ—¥", ascending=False)
styled_df = df_disp.style.apply(highlight_alert, axis=1)

event = st.dataframe(
    styled_df, use_container_width=True, hide_index=True, on_select="rerun", selection_mode="multi-row",
    column_config={"æœ€çµ‚æ›´æ–°æ—¥": "æ—¥æ™‚", "åœ¨åº«æ•°": "åœ¨åº«", "æ•°é‡": st.column_config.NumberColumn(format="%d")}
)

# --- 5. æ“ä½œãƒ‘ãƒãƒ«ï¼šä¸€æ‹¬ç·¨é›† ---
st.divider()
selected_indices = event.selection.rows
selected_data_list = df_disp.iloc[selected_indices] if selected_indices else pd.DataFrame()

if not selected_data_list.empty:
    n_selected = len(selected_data_list)
    st.markdown(f"### ğŸ“‹ {n_selected} ä»¶ã®ä¸€æ‹¬æ“ä½œ")
    
    user_list = ["-- é¸æŠ --"] + USERS
    default_user_idx = 0
    if "last_user" in st.session_state and st.session_state.last_user in user_list:
        default_user_idx = user_list.index(st.session_state.last_user)
    
    user_name = st.selectbox("æ‹…å½“è€…ã‚’é¸ã‚“ã§ãã ã•ã„", user_list, index=default_user_idx)
    
    if user_name != "-- é¸æŠ --":
        st.info("ğŸ’¡ å¤‰æ›´ã—ãŸã„é …ç›®ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        update_payload = {}
        for i, row in selected_data_list.iterrows():
            item_id = f"{row['å•†å“å']}_{row['ã‚µã‚¤ã‚º']}_{row['åœ°å']}"
            with st.expander(f"ğŸ“Œ {row['å•†å“å']} ({row['ã‚µã‚¤ã‚º']} / {row['åœ°å']}) - ç¾åœ¨ã®åœ¨åº«: {row['åœ¨åº«æ•°']}", expanded=True):
                col1, col2, col3, col4, col5 = st.columns([1, 1.2, 1.2, 1, 0.8])
                
                with col1:
                    m_type = st.radio("", ["å…¥åº«", "å‡ºåº«", "æ•°é‡å¤‰æ›´ãªã—"], horizontal=True, key=f"type_{i}")
                with col2:
                    m_qty = st.number_input("æ•°é‡", min_value=0, value=0, key=f"qty_{i}")
                with col3:
                    new_loc = st.text_input("åœ°åã®å¤‰æ›´", value=row['åœ°å'], key=f"loc_{i}")
                with col4:
                    new_alert = st.number_input("ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–", min_value=0, value=int(row['ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–']), key=f"alt_{i}")
                with col5:
                    is_delete = st.checkbox("ğŸ—‘ï¸ è¡Œã‚’å‰Šé™¤", key=f"del_{i}")
                
                update_payload[i] = {
                    "type": m_type, "qty": m_qty, "loc": new_loc, 
                    "alert": new_alert, "delete": is_delete, "orig_data": row
                }
        
        if st.button("ğŸ”„ å…¨ã¦ã®å¤‰æ›´ã‚’ç¢ºå®šã™ã‚‹", type="primary", use_container_width=True):
            st.session_state.last_user = user_name
            now = get_now_jst()
            new_logs = []
            
            # å…ƒã®df_stockã‚’æ›´æ–°
            for idx_in_disp, p in update_payload.items():
                row = p["orig_data"]
                # å…ƒãƒ‡ãƒ¼ã‚¿ã®ç‰¹å®š
                target_mask = (df_stock["å•†å“å"] == row["å•†å“å"]) & \
                              (df_stock["ã‚µã‚¤ã‚º"] == row["ã‚µã‚¤ã‚º"]) & \
                              (df_stock["åœ°å"] == row["åœ°å"])
                
                if target_mask.any():
                    orig_idx = df_stock[target_mask].index[0]
                    
                    if p["delete"]:
                        df_stock = df_stock.drop(orig_idx)
                        new_logs.append({
                            "æ—¥æ™‚": now, "å•†å“å": row["å•†å“å"], "ã‚µã‚¤ã‚º": row["ã‚µã‚¤ã‚º"], 
                            "åœ°å": row["åœ°å"], "åŒºåˆ†": "å‰Šé™¤", "æ•°é‡": 0, "æ‹…å½“è€…": user_name
                        })
                    else:
                        # åœ¨åº«å¤‰å‹•
                        if p["type"] == "å…¥åº«":
                            df_stock.at[orig_idx, "åœ¨åº«æ•°"] += p["qty"]
                        elif p["type"] == "å‡ºåº«":
                            df_stock.at[orig_idx, "åœ¨åº«æ•°"] -= p["qty"]
                        
                        # åœ°åãƒ»åŸºæº–ã®æ›´æ–°
                        df_stock.at[orig_idx, "åœ°å"] = p["loc"]
                        df_stock.at[orig_idx, "ã‚¢ãƒ©ãƒ¼ãƒˆåŸºæº–"] = p["alert"]
                        df_stock.at[orig_idx, "æœ€çµ‚æ›´æ–°æ—¥"] = now
                        
                        # ãƒ­ã‚°ï¼ˆæ•°é‡ãŒå‹•ã„ãŸå ´åˆã®ã¿ï¼‰
                        if p["qty"] > 0:
                            new_logs.append({
                                "æ—¥æ™‚": now, "å•†å“å": row["å•†å“å"], "ã‚µã‚¤ã‚º": row["ã‚µã‚¤ã‚º"], 
                                "åœ°å": p["loc"], "åŒºåˆ†": p["type"], "æ•°é‡": p["qty"], "æ‹…å½“è€…": user_name
                            })
                        # åœ°åãŒå¤‰ã‚ã£ãŸå ´åˆã®ãƒ­ã‚°ï¼ˆä»»æ„ï¼‰
                        if p["loc"] != row["åœ°å"]:
                            new_logs.append({
                                "æ—¥æ™‚": now, "å•†å“å": row["å•†å“å"], "ã‚µã‚¤ã‚º": row["ã‚µã‚¤ã‚º"], 
                                "åœ°å": p["loc"], "åŒºåˆ†": "åœ°åå¤‰æ›´", "æ•°é‡": 0, "æ‹…å½“è€…": user_name
                            })

            if update_github_data(FILE_PATH_STOCK, df_stock, sha_stock, "Batch Edit") and \
               (not new_logs or update_github_data(FILE_PATH_LOG, pd.concat([df_log, pd.DataFrame(new_logs)], ignore_index=True), sha_log, "Batch Log")):
                st.rerun()
else:
    st.info("ğŸ’¡ **ä¸€è¦§ã§è¤‡æ•°ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã‚‹ã¨ã€ä¸€æ‹¬ç·¨é›†ãƒ»å‰Šé™¤ãƒ‘ãƒãƒ«ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚**")

# --- 6. å±¥æ­´è¡¨ç¤º ---
st.divider()
log_h_col1, log_h_col2, log_h_col3 = st.columns([1.5, 2, 2])
with log_h_col1:
    st.subheader("ğŸ“œ å…¥å‡ºåº«å±¥æ­´")
with log_h_col2:
    log_types = st.multiselect("åŒºåˆ†:", ["å…¥åº«", "å‡ºåº«", "å‰Šé™¤", "åœ°åå¤‰æ›´", "æ–°è¦ç™»éŒ²"], default=["å…¥åº«", "å‡ºåº«", "æ–°è¦ç™»éŒ²"], label_visibility="collapsed")
with log_h_col3:
    log_date_range = st.date_input("æœŸé–“é¸æŠ", value=(dt.date.today() - dt.timedelta(days=7), dt.date.today()), label_visibility="collapsed")

if not df_log.empty:
    df_log_filt = df_log.copy()
    if isinstance(log_date_range, tuple) and len(log_date_range) == 2:
        start_date, end_date = log_date_range
        df_log_filt["æ—¥æ™‚_dt"] = pd.to_datetime(df_log_filt["æ—¥æ™‚"]).dt.date
        df_log_filt = df_log_filt[(df_log_filt["æ—¥æ™‚_dt"] >= start_date) & (df_log_filt["æ—¥æ™‚_dt"] <= end_date)]
    if log_types:
        df_log_filt = df_log_filt[df_log_filt["åŒºåˆ†"].isin(log_types)]
    if sync_logs:
        if s_item != "ã™ã¹ã¦": df_log_filt = df_log_filt[df_log_filt["å•†å“å"] == s_item]
        if s_size != "ã™ã¹ã¦": df_log_filt = df_log_filt[df_log_filt["ã‚µã‚¤ã‚º"] == s_size]
        if search_loc.strip(): df_log_filt = df_log_filt[df_log_filt["åœ°å"].astype(str).str.contains(search_loc, na=False)]

    st.dataframe(
        df_log_filt[["æ—¥æ™‚", "å•†å“å", "ã‚µã‚¤ã‚º", "åœ°å", "åŒºåˆ†", "æ•°é‡", "æ‹…å½“è€…"]].sort_values("æ—¥æ™‚", ascending=False), 
        use_container_width=True, hide_index=True,
        column_config={"æ•°é‡": st.column_config.NumberColumn("æ•°", format="%d")}
    )
